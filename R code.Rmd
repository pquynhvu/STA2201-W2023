---
title: "STA2201 R code"
author: "Quynh Vu"
date: "`r Sys.Date()`"
output: pdf_document
---

```{r setup, include=FALSE}
# knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(
  echo = FALSE,
  message = FALSE,
  warning = FALSE,
  error = FALSE, 
  out.width = "100%",
  fig.width = 10,
  fig.height = 6.7, 
  fig.retina = 3,
  cache = FALSE)
```

# Week 1

```{r echo=TRUE}
library(tidyverse)
```

```{r echo=TRUE}
dm <- read_table("https://www.prdh.umontreal.ca/BDLC/data/ont/Mx_1x1.txt", 
                 skip = 2, col_types = "dcddd")
head(dm)
# skip: Number of lines to skip before reading data.
# col_types: d = double; c = character
```

## 1. Tidyverse functions

The pipe `|>` or `%>%` in `magrittr` package (read as "and then") is used to manipulate the tibbles

## a) Piping, filtering, selecting, arranging

e.g. Year 1935 
```{r echo = TRUE}
filter(dm, Year==1935) # or
dm |> filter(Year==1935)
```

e.g. 10 year olds in Year 1935

```{r echo=TRUE}
dm |> filter(Year==1935, Age==10)
```

e.g. 10 year olds in 1935 who were female

```{r echo=TRUE}
dm |> filter(Year==1935, Age==10) |> select(Female)
```

e.g. Remove column

```{r echo=TRUE}
colnames(dm)
dm |> select(-Total)
```

e.g. sort Year in descending order

```{r echo=TRUE}
dm |> arrange(-Year)
```

### b) Grouping, summarizing, mutating

e.g. ratio of male to female mortality at each age and year

```{r echo=TRUE}
dm <- dm |> mutate(mf_ratio = Male/Female) # create new variables
```

e.g. mean female mortality rate by age over all the years

```{r echo=TRUE}
summary_mean <- dm |> group_by(Age) |> summarize(mean_mortality = mean(Female, na.rm = TRUE)) 
dim(summary_mean)
dim(dm)
```
	
e.g. apply `mean` function across Male and Female columns by `across`

```{r echo=TRUE}
dm |> group_by(Age) |> summarize(mean_mortality_f = mean(Female, na.rm = TRUE),
                                 mean_mortality_m = mean(Male, na.rm = TRUE))
```

```{r echo=TRUE}
dm |> group_by(Age) |> summarize(across(Male:Female, mean))
```
		       
The `summarize` function produces summary statistics

### c) Pivoting

e.g. wide to long

```{r echo=TRUE}
dm_long <- dm |> select(-mf_ratio) |> 
  					     pivot_longer(Female:Total, names_to = "sex", values_to = "mortality")
head(dm_long)
```

e.g. long to wide

```{r echo=TRUE}
dm_long |> pivot_wider(names_from = "sex", values_from = "mortality")  
head(dm_long)
```

## 2. ggplot()

e.g. mortality rates for 30 year old males over time
     
```{r echo=TRUE}
d_to_plot <- dm |> filter(Age==30) |> select(Year, Male)
head(d_to_plot)
```

```{r echo=TRUE}
p <- ggplot(data = d_to_plot, aes(x = Year, y = Male))
p + # an empty box
  geom_line() + # specify that we want a line plot
  geom_line(color = "firebrick4") + # color of the line
  labs(title = "30 year old Male mortality rates over time, Ontario", 
       subtitle = "", y = "Mortality rate") + 
  theme_bw(base_size = 14)
```

e.g. trends for 30-year old males and females on the one plot

```{r echo=TRUE}
dp <- dm |> filter(Age==30) |> select(Year:Male) |> 
            pivot_longer(Female:Male, names_to = "Sex", values_to = "Mortality")
head(dp)
```

# Week 2: Exploratory data analysis (EDA) and data visualization

```{r echo=TRUE}
library(opendatatoronto) # for dataset
library(opendatatoronto)
library(tidyverse)
library(stringr)
library(skimr)  # EDA
library(visdat) # EDA
library(janitor)
library(lubridate)
library(ggrepel)
```

```{r echo=TRUE}
all_data <- list_packages(limit = 500) # to look whats available
head(all_data)
# obtained code from searching data frame above
res <- list_package_resources("996cfe8d-fb35-40ce-b569-698d51fc683b") 
 # extracts the first complete match from each string
res <- res |> mutate(year = str_extract(name, "202.?"))
head(res)
delay_2022_ids <- res |> filter(year==2022)|> select(id) |> 
                         pull() # Extract a single column
delay_2022 <- get_resource(delay_2022_ids) # download a resource into R
# from janitor to make the column names nicer to work with
delay_2022 <- clean_names(delay_2022) 
```

```{r echo=TRUE}
# download the delay code and readme, as reference. 
delay_codes <- get_resource("3900e649-f31e-4b79-9f20-4731bbfd94f7")
delay_data_codebook <- get_resource("ca43ac3d-3940-4315-889b-a9375e7b8aa4")
```

```{r echo=TRUE}
head(delay_2022)
```

## 1. EDA and data vizualization

It's important to always keep in mind: 

  * what should your variables look like (type, values, distribution, etc)

  * what would be surprising (outliers etc)
  
  * what is your end goal (here, it might be understanding factors associated with delays, e.g. stations, time of year, time of day, etc)

In any data analysis project, if it turns out you have data issues, surprising values, missing data etc, it's important you **document** anything you found and the subsequent steps or **assumptions** you made before moving onto your data analysis/modeling. 

## a) Data checks

**Sanity Checks:** We need to check variables should be what they say they are. If they aren't, the natural next question is to what to do with issues (recode? remove?)

```{r echo=TRUE}
unique(delay_2022$day)  # check days of week
unique(delay_2022$line) # some have obvious recodes, others, not so much.
# skim a data frame, getting useful summary statistics
# skim(delay_2022)
```

**Missing values:**

```{r echo=TRUE}
delay_2022 |> 
           summarize(across(everything(), ~ sum(is.na(.x)))) # Calculate number of NAs by column
# vis_dat(delay_2022)  visualises a data.frame
# vis_miss(delay_2022) to see how missing values are distributed
```

**Duplicates:**

```{r echo=TRUE}
get_dupes(delay_2022) # from janitor package
delay_2022 <-delay_2022 |> distinct() # subset distinct/unique rows
```

## b) Visualizing distributions

```{r echo=TRUE}
## Removing the observations that have non-standardized lines
delay_2022 <- delay_2022 |> filter(line %in% c("BD", "YU", "SHP", "SRT"))

ggp1 <- ggplot(data = delay_2022) + geom_histogram(aes(x = min_delay))

ggp2 <- ggplot(data = delay_2022) + geom_histogram(aes(x = min_delay)) +
        labs(title = "Logged Scale") +
        scale_x_log10() # on logged scale
require(gridExtra)
grid.arrange(ggp1, ggp2, ncol=2)
```

Our initial EDA hinted at an outlying delay time, let's take a look at the largest delays below. Join the `delay_codes` dataset to see what the delay is. (Have to do some mangling as SRT has different codes).

```{r echo=TRUE}
delay_2022 <- delay_2022 |> 
              left_join(delay_codes |> rename(code = `SUB RMENU CODE`, 
                                              code_desc = `CODE DESCRIPTION...3`) |> 
                                       select(code, code_desc)) 
delay_2022 <- delay_2022 |>
                         mutate(code_srt = ifelse(line=="SRT", code, "NA")) |> 
                         left_join(delay_codes |> rename(code_srt = `SRT RMENU CODE`, 
                                                         code_desc_srt = `CODE DESCRIPTION...7`) |> 
                         select(code_srt, code_desc_srt))  |> 
                         mutate(code = ifelse(code_srt=="NA", code, code_srt),
                                code_desc = ifelse(is.na(code_desc_srt), code_desc, code_desc_srt)) |> 
                                select(-code_srt, -code_desc_srt)
```

The largest delay is due to "Signals Other".

```{r echo=TRUE}
delay_2022 |> 
           left_join(delay_codes |> 
           rename(code = `SUB RMENU CODE`, code_desc = `CODE DESCRIPTION...3`) |> 
           select(code, code_desc)) |> 
           arrange(-min_delay) |> 
           select(date, time, station, line, min_delay, code, code_desc)
```

# c) Grouping and small multiples

A quick and powerful visualization technique is to group the data by a variable of interest, e.g. `line`

```{r echo=TRUE}
ggp3 <- ggplot(data = delay_2022) + 
        geom_histogram(aes(x = min_delay, y = ..density.., fill = line), position = 'dodge', bins = 10) +
        labs(title = "Density") +
        scale_x_log10()
ggp4 <- ggplot(data = delay_2022) + 
        geom_histogram(aes(x = min_delay, fill = line), position = 'dodge', bins = 10) + 
        labs(title = "Frequency") +
        scale_x_log10()
require(gridExtra)
grid.arrange(ggp3, ggp4, ncol = 2)
```

If you want to group by more than one variable, facets are good:

```{r echo=TRUE}
ggplot(data = delay_2022) + 
       geom_density(aes(x = min_delay, color = day), bw = .08) + 
       scale_x_log10() + 
       facet_wrap(~line)
```

The station names are a mess. Try and clean up the station names a bit by taking just the first word (or, the first two if it starts with "ST"):

```{r echo=TRUE}
delay_2022 <- delay_2022 |> 
                         mutate(station_clean = ifelse(str_starts(station, "ST"), 
                                                       word(station, 1,2), word(station, 1)))
head(delay_2022)
```

## d) Visualizing time series

Daily plot is messy (you can check for yourself). Let's look by week to see if there's any seasonality. The `lubridate` package has lots of helpful functions that deal with date variables. First, mean delay (of those that were delayed more than 0 mins):

```{r echo=TRUE}
delay_2022 |> filter(min_delay>0) |> 
              mutate(week = week(date)) |> # Get/set weeks component of a date-time
              group_by(week, line) |> 
              summarise(mean_delay = mean(min_delay)) |> 
              ggplot(aes(week, mean_delay, color = line)) + 
              geom_point() + 
              geom_smooth() + 
              facet_grid(~line)
```

What about proportion of delays that were greater than 10 mins?

```{r echo=TRUE}
delay_2022 |> mutate(week = week(date)) |> 
              group_by(week, line) |> 
              summarise(prop_delay = sum(min_delay>10)/n()) |> 
              ggplot(aes(week, prop_delay, color = line)) + 
              geom_point() + 
              geom_smooth() + 
              facet_grid(~line)
```

## e) Visualizing relationships

Note that **scatter plots** are a good precursor to modeling, to visualize relationships between continuous variables. Nothing obvious to plot here, but easy to do with `geom_point`. Look at top five reasons for delay by station. Do they differ? Think about how this could be modeled. 

```{r echo=TRUE}
delay_2022 |> group_by(line, code_desc) |>
              summarise(mean_delay = mean(min_delay)) |>
              arrange(-mean_delay) |>
              slice(1:5) |> # subset rows using their positions
              ggplot(aes(x = code_desc, y = mean_delay)) +
              geom_col() + 
              facet_wrap(vars(line), scales = "free_y", nrow = 4) +
              coord_flip()
```

## f) PCA (additional)

Principal components analysis is a really powerful exploratory tool, particularly when you have a lot of variables. It allows you to pick up potential clusters and/or outliers that can help to inform model building. 

Let's do a quick (and imperfect) example looking at types of delays by station. The delay categories are a bit of a mess, and there's hundreds of them. As a simple start, let's just take the first word: 

```{r echo=TRUE}
delay_2022 <- delay_2022 |> 
              mutate(code_red = case_when(str_starts(code_desc, "No") ~ word(code_desc, 1, 2),
                                          str_starts(code_desc, "Operator") ~ word(code_desc, 1,2),
                                          TRUE ~ word(code_desc,1)))
```

Let's also just restrict the analysis to causes that happen at least 50 times over 2022 To do the PCA, the dataframe also needs to be switched to wide format:

```{r echo=TRUE}
dwide <- delay_2022 |> group_by(line, station_clean) |> 
                       mutate(n_obs = n()) |> 
                       filter(n_obs>1) |> 
                       group_by(code_red) |> 
                       mutate(tot_delay = n()) |> 
                       arrange(tot_delay) |> 
                       filter(tot_delay>50) |> 
                       group_by(line, station_clean, code_red) |> 
                       summarise(n_delay = n()) |> 
                       pivot_wider(names_from = code_red, values_from = n_delay) |> 
                       mutate(across(everything(), ~ replace_na(.x, 0)))
```

Do the PCA:

```{r echo=TRUE}
delay_pca <- prcomp(dwide[,3:ncol(dwide)])
df_out <- as_tibble(delay_pca$x)
df_out <- bind_cols(dwide |> select(line, station_clean), df_out)
head(df_out)
```

Plot the first two PCs, and label some outlying stations:

```{r echo=TRUE}
ggp5 <- ggplot(df_out,aes(x=PC1,y=PC2,color=line )) + 
        geom_point() + 
        geom_text_repel(data = df_out |> 
                                      filter(PC2>100|PC1<100*-1), aes(label = station_clean))
```

Plot the factor loadings. Some evidence of public v operator?

```{r echo=TRUE}
df_out_r <- as_tibble(delay_pca$rotation)
df_out_r$feature <- colnames(dwide[,3:ncol(dwide)])
df_out_r
```

```{r echo=TRUE}
ggp6 <- ggplot(df_out_r,aes(x=PC1,y=PC2,label=feature )) + geom_text_repel()
require(gridExtra)
grid.arrange(ggp5, ggp6, ncol = 2)
```

